\makeheading{Lecture 8}{\printdate{2023-01-31}}%chktex 8
\section{Lecture 8: Test of Overall Regression}
\begin{Definition}{Sum of Squares Total, Residual, Error}{}
    \begin{align*}
        \bar{Y}
             & =\frac{1}{n}\sum_{i=1}^{n}Y_i,      \\
        \SST & =\sum_{i=1}^{n}(Y_i-\bar{Y})^2,     \\
        \SSR & =\sum_{i=1}^{n}(\hat{Y}-\bar{Y})^2, \\
        \SSE & =\sum_{i=1}^{n}(Y_i-\hat{Y}_i)^2.
    \end{align*}
    $ \SST $ is the \textbf{sum of squares total},
    $ \SSR $ is the \textbf{sum of squares residual},
    and $ \SSE $ is the \textbf{sum of squares error}.
\end{Definition}
\begin{Theorem}{}{}
    \begin{enumerate}[(i)]
        \item $ \SST=\Vector{Y}'(\Matrix{I}-\tfrac{1}{n}\Matrix{J})\Vector{Y} $.
        \item $ \SSR=\Vector{Y}'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{Y} $.
        \item $ \SSE=\Vector{Y}'(\Matrix{I}-\Matrix{H})\Vector{Y} $.
    \end{enumerate}
    Hence, $ \SST=\SSR+\SSE $.
    \tcblower{}
    \textbf{Proof}:
    \begin{enumerate}[(i)]
        \item Sum of Squares Total:
              \begin{align*}
                  \SST
                   & =\sum_{i=1}^{n}(Y_i-\bar{Y})^2                                                       \\
                   & =(\Vector{Y}-\bar{Y}\Vector{j})'(\Vector{Y}-\bar{Y}\Vector{j})                       \\
                   & =\Vector{Y}'\Vector{Y}-2\bar{Y}\Vector{Y}'\Vector{j}+\bar{Y}^2 \Vector{j}'\Vector{j} \\
                   & =\Vector{Y}'\Vector{Y}-2n\bar{Y}^2+n\bar{Y}^2                                        \\
                   & =\Vector{Y}'\Vector{Y}-n\bar{Y}^2                                                    \\
                   & =\Vector{Y}'\Vector{Y}-\tfrac{1}{n}\Vector{Y}'\Vector{j}\Vector{j}'\Vector{Y}        \\
                   & =\Vector{Y}'(\Matrix{I}-\tfrac{1}{n}\Matrix{J})\Vector{Y}.
              \end{align*}
        \item Sum of Squares Regression:
              \begin{align*}
                  \SSR
                   & =\sum_{i=1}^{n}(\hat{Y}_i-\bar{Y})^2                                                                                                             \\
                   & =(\hat{\Vector{Y}}-\bar{Y}\Vector{j})'(\hat{\Vector{Y}}-\bar{Y}\Vector{j})                                                                       \\
                   & =(\Matrix{H}\Vector{Y}-\bar{Y}\Vector{j})'(\Matrix{H}\Vector{Y}-\bar{Y}\Vector{j})                                                               \\
                   & =\Vector{Y}'\Matrix{HH}\Vector{Y}-2\bar{Y}\Vector{Y}'\Matrix{H}\Vector{j}+\bar{Y}^2 \Vector{j}'\Vector{j}                                        \\
                   & =\Vector{Y}'\Matrix{H}^2 \Vector{Y}-\tfrac{2}{n}\Vector{Y}'\Matrix{H}\Vector{j}\Vector{j}'\Vector{Y}+\tfrac{1}{n}\Vector{Y}'\Matrix{J}\Vector{Y} \\
                   & =\Vector{Y}'\Matrix{H}\Vector{Y}-\tfrac{2}{n}\Vector{Y}'\Matrix{H}\Matrix{J}\Vector{Y}+\tfrac{1}{n}\Vector{Y}'\Matrix{J}\Vector{Y}               \\
                   & =\Vector{Y}'\Matrix{H}\Vector{Y}-\tfrac{2}{n}\Vector{Y}'\Matrix{J}\Vector{Y}+\tfrac{1}{n}\Vector{Y}'\Matrix{J}\Vector{Y}                         \\
                   & =\Vector{Y}'\Matrix{H}\Vector{Y}-\tfrac{1}{n}\Vector{Y}'\Matrix{J}\Vector{Y}                                                                     \\
                   & =\Vector{Y}'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{Y}
              \end{align*}
              since $ \Matrix{H}^2=\Matrix{H} $, $ \Matrix{HX}=\Matrix{X} $, and $ \Matrix{H}\Vector{j}=\Vector{j}\implies \Matrix{HJ}=\Matrix{J} $.
        \item Sum of Squares Error:
              \begin{align*}
                  \SSE
                   & =\sum_{i=1}^{n}(Y_i-\hat{Y}_i)                                                   \\
                   & =(\Vector{Y}-\hat{\Vector{Y}})'(\Vector{Y}-\hat{\Vector{Y}})                     \\
                   & =(\Vector{Y}-\Matrix{H}\Vector{Y})'(\Vector{Y}-\Matrix{H}\Vector{Y})             \\
                   & =\bigl((\Matrix{I}-\Matrix{H})\Vector{Y}\bigr)'(\Matrix{I}-\Matrix{H})\Vector{Y} \\
                   & =\Vector{Y}'(\Matrix{I}-\Matrix{H})^2 \Vector{Y}                                 \\
                   & =\Vector{Y}'(\Matrix{I}-\Matrix{H})\Vector{Y}
              \end{align*}
              since $ (\Matrix{I}-\Matrix{H})^2=\Matrix{I}-\Matrix{H} $.
    \end{enumerate}
    Therefore,
    \[ \Matrix{I}-\Matrix{H}+\Matrix{H}-\tfrac{1}{n}\Matrix{J}=\Matrix{I}-\tfrac{1}{n}\Matrix{J}\implies \SST=\SSR+\SSE. \]
\end{Theorem}
\begin{Theorem}{}{}
    \begin{enumerate}[(1)]
        \item $ \SSR/\sigma^2 \sim \chi^2(k,\lambda) $ with
              \begin{align*}
                  \lambda
                   & =\frac{1}{2\sigma^2}(\Matrix{X}\Vector{\beta})'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Matrix{X}\Vector{\beta}            \\
                   & =\frac{1}{2\sigma^2}(\Matrix{X}_1 \Vector{\beta}_1)'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Matrix{X}_1 \Vector{\beta}_1,
              \end{align*}
              where
              \[ \Vector{\beta}_1=\begin{pmatrix}
                      \beta_1 \\
                      \vdots  \\
                      \beta_k
                  \end{pmatrix},\qquad \Matrix{X}_1=\begin{pmatrix}
                      X_{11} & \cdots & X_{1k} \\
                      \vdots & \ddots & \vdots \\
                      X_{n1} & \cdots & X_{nk}
                  \end{pmatrix}. \]
        \item $ \SSR $ and $ \SSE $ are independent.
    \end{enumerate}
    \tcblower{}
    \textbf{Proof}:
    \begin{enumerate}[(1)]
        \item First result:
              \[ \frac{\SSR}{\sigma^2}=\frac{\Vector{Y}'}{\sigma}(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\frac{\Vector{Y}}{\sigma} \]
              with
              \[ \frac{\Vector{Y}}{\sigma}\sim \MN*{\frac{\Matrix{X}\Vector{\beta}}{\sigma},\Matrix{I}}. \]
              Since
              \begin{align*}
                  (\Matrix{H}-\tfrac{1}{n}\Matrix{J})^2
                   & =\Matrix{H}^2-2 \tfrac{1}{n}\Matrix{H}\Matrix{J}+\frac{1}{n^2}\Matrix{J}^2 \\
                   & =\Matrix{H}-2\tfrac{1}{n}\Matrix{J}+\tfrac{1}{n}\Matrix{J}                 \\
                   & =\Matrix{H}-\tfrac{1}{n}J
              \end{align*}
              it follows from Theorem 4.1 that $ \SSR/\sigma^2 \sim \chi^2(r,\lambda) $ with
              \[ r=\rank{\Matrix{H}-\tfrac{1}{n}\Matrix{J}}=\tr{\Matrix{H}-\tfrac{1}{n}\Matrix{J}}=k+1-1=k \]
              and
              \[ \lambda=\frac{1}{n}\biggl(\frac{\Matrix{X}\Vector{\beta}}{\sigma}\biggr)'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\frac{\Matrix{X}\Vector{\beta}}{\sigma}. \]
              Write
              \[ \Vector{\beta}=\begin{pmatrix}
                      \beta_0 \\
                      \Vector{\beta}_1
                  \end{pmatrix},\qquad
                  \Matrix{X}=\begin{pmatrix}
                      \Vector{j} & \Matrix{X}_1
                  \end{pmatrix}. \]
              Then, $ \Matrix{X}\Vector{\beta}=\beta_0 \Vector{j}+\Matrix{X}_1 \Vector{\beta}_1 $ implies
              \begin{align*}
                  \lambda
                   & =\frac{1}{2}\biggl(\frac{\beta_0 \Vector{j}+\Matrix{X}_1 \Vector{\beta}_1}{\sigma}\biggr)'
                  (\Matrix{H}-\tfrac{1}{n}\Matrix{J})\frac{\beta_0 \Vector{j}+\Matrix{X}_1 \Vector{\beta}_1}{\sigma}                                                                                                \\
                   & =\frac{1}{2\sigma^2}\Bigl[(\Matrix{X}_1 \Vector{\beta}_1)(\Matrix{H}-\tfrac{1}{n}\Matrix{J})(\Matrix{X}_1 \Vector{\beta}_1)+\beta_0^2 \Vector{j}'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{j}
                  +2 \beta_0(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{j}\Bigr]                                                                                                                                     \\
                   & =\frac{1}{2\sigma^2}(\Matrix{X}_1\Vector{\beta}_1)'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Matrix{X}_1 \Vector{\beta}_1
              \end{align*}
              since
              \[ (\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{j}=\Matrix{H}\Vector{j}-\tfrac{1}{n}\Matrix{J}\Vector{j}=\Vector{j}-\tfrac{1}{n}n \Vector{j}=0. \]
        \item Note that
              \begin{align*}
                  \SSR & =\Vector{Y}'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{Y}=\Vector{Y}'\Matrix{A}\Vector{Y}. \\
                  \SSE & =\Vector{Y}'(\Matrix{I}-\Matrix{H})\Vector{Y}=\Vector{Y}'\Matrix{B}\Vector{Y}.
              \end{align*}
              Note that $ \Vector{Y}\sim \MN{\Matrix{X}\Vector{\beta},\sigma^2 \Matrix{I}} $. Note that $ \Matrix{H}-\tfrac{1}{n}\Matrix{J} $
              and $ \Matrix{I}-\Matrix{H} $ are symmetric matrices of the same dimension.
              \begin{align*}
                  \Matrix{A}\sigma^2 \Matrix{I}\Matrix{B}
                   & =\sigma^2 \Matrix{A}\Matrix{B}                                                             \\
                   & =\sigma^2 (\Matrix{H}-\tfrac{1}{n}\Matrix{J})(\Matrix{I}-\Matrix{H})                       \\
                   & =\sigma^2(\Matrix{H}-\tfrac{1}{n}\Matrix{J}-\Matrix{H}^2+\tfrac{1}{n}\Matrix{J}\Matrix{H}) \\
                   & =\sigma^2(\Matrix{H}-\tfrac{1}{n}\Matrix{J}-\Matrix{H}+\tfrac{1}{n}\Matrix{J})             \\
                   & =\sigma^2 \Matrix{O}                                                                       \\
                   & =\Matrix{O}.
              \end{align*}
              Therefore, $ \SSR $ and $ \SSE $ are independent by Theorem 5.2.
    \end{enumerate}
\end{Theorem}
\begin{Remark}{}{}
    By Theorem 7.4, we have $ \SSE/\sigma^2 \sim \chi^2(n-(k+1)) $, and
    $ \SST/\sigma^2 \sim \chi^2(n-1,\lambda) $.
\end{Remark}
\begin{Remark}{}{}
    \begin{align*}
        \E{\SSR}
         & =\sigma^2\E*{\frac{\SSR}{\sigma^2}}                                                                                                                     \\
         & =\sigma^2 \sum_{i=1}^{k}\E{X_i^2}                                                                            &  & \text{where $ X_i \sim \N{\mu_i,1} $} \\
         & =\sigma^2\biggl(\sum_{i=1}^{n}\bigl(\Var{X_i}+\mu_i^2\bigr)\biggr)                                                                                      \\
         & =\sigma^2(k+2\lambda)                                                                                                                                   \\
         & =k\sigma^2+2\sigma^2\lambda                                                                                                                             \\
         & =k\sigma^2+(\Matrix{X}_1 \Vector{\beta}_1)'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Matrix{X}_1 \Vector{\beta}_1.
    \end{align*}
\end{Remark}
\subsection*{ANOVA Table for Hypothesis Test of $ \HN $: $ \Vector{\beta}_1=\Vector{0} $ versus $ \HA $: $ \Vector{\beta}_1\ne \Vector{0} $}
\[ \begin{array}{lllll}
        \toprule
        \text{Source of Variation}     & \text{Degrees of Freedom} & \text{Sum of Squares} & \text{Mean Square} & \text{Expected Mean Square}                                                                                          \\
        \midrule
        \text{Due to }\Vector{\beta}_1 & k                         & \SSR                  & \MSR               & \sigma^2+\frac{1}{k}(\Matrix{X}_1 \Vector{\beta}_1)'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{X}_1 \Vector{\beta}_1 \\
        \text{Error}                   & n-(k+1)                   & \SSE                  & \MSE               & \sigma^2                                                                                                             \\
        \text{Total}                   & n-1                       & \SST                                                                                                                                                              \\
        \bottomrule
    \end{array} \]
Note that under $ \HN $, $ \frac{1}{k}(\Matrix{X}_1 \Vector{\beta}_1)'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{X}_1 \Vector{\beta}_1=0 $.
\begin{align*}
    \E{\MSR}
     & =\E*{\frac{\SSR}{k}}                                                                                                               \\
     & =\frac{1}{k}\bigl[\sigma^2 k+(\Matrix{X}_1 \Vector{\beta}_1)(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{X}_1 \Vector{\beta}_1\bigr] \\
     & =\sigma^2+\frac{1}{k}(\Matrix{X}_1 \Vector{\beta}_1)'(\Matrix{H}-\tfrac{1}{n}\Matrix{J})\Vector{X}_1 \Vector{\beta}_1.             \\
    \E{\MSE}
     & =\E*{\frac{\SSE}{n-(k+1)}}                                                                                                         \\
     & =\frac{(n-(k+1))\sigma^2}{n-(k+1)}                                                                                                 \\
     & =\sigma^2.
\end{align*}
Test Statistic:
\[ F=\frac{\SSR/k}{\SSE/(n-(k+1))}\sim F(k,n-(k+1)). \]
Reject $ \HN $ if $ F>F_{\alpha}(k,n-(k+1)) $. If $ \HN $ holds, then $ \lambda=0 $ implies
$ \SSR \sim \chi^2(k) $ and $ \SSE \sim \chi^2(n-(k+1)) $. Furthermore, note that
if $ X $ and $ Y $ are independent, then $ f(X) $ and $ g(Y) $ are independent, so
\begin{align*}
    \E{F}
                        & =\E*{\frac{\SSR/k}{\SSE/(n-(k+1))}}            \\
                        & =\frac{n-(k+1)}{k}\E{\SSR}\E*{\frac{1}{\SSE}}. \\
    \E*{\frac{\SSR}{k}} & =\sigma^2\iff \E*{\SSR}=k\sigma^2.
\end{align*}
Hold tight for the hard part (you can skip this part if you know the mean of the
\href{https://en.wikipedia.org/wiki/Inverse-chi-squared_distribution}{\emph{inverse-chi-squared distribution}}),
\begin{align*}
    \E*{\frac{\sigma^2}{\SSE}}
     & =\int_{0}^{\infty}\frac{1}{y}\frac{1}{2^{(n-k-1)/2}\Gamma\bigl(\frac{n-k-1}{2}\bigr)}
    y^{(n-k-1)/2-1}e^{-y/2}\odif{y}                                                                              \\
     & =2^{-(n-k-1)/2}\frac{\Gamma\bigl(\frac{n-k-1}{2}-1\bigr)}{\Gamma\bigl(\frac{n-k-1}{2}\bigr)}\times        \\
     & \phantom{=}\quad 2^{(n-k-1)/2-1} \underbrace{\frac{1}{\Gamma\bigl(\frac{n-k-1}{2}-1\bigr)2^{(n-k-1)/2-1}}
    \int_{0}^{\infty}y^{((n-k-1)/2-1)-1}e^{-y/2}\odif{y}}_{=1\text{ by Gamma distribution}}                      \\
     & =\frac{1}{2}\frac{1}{(n-k-1)/2-1}                                                                         \\
     & =\frac{1}{n-k-3}.
\end{align*}
Hence,
\[ \E*{\frac{1}{\SSE}}=\frac{1}{\sigma^2(n-k-3)}. \]
Therefore,
\[ \E{F}=\frac{n-k-1}{k}\E{\SSR}\E*{\frac{1}{\SSE}}=
    \frac{n-k-1}{k}k\sigma^2\frac{1}{\sigma^2(n-k-3)}=\frac{n-k-1}{n-k-3}. \]