\makeheading{Lecture 18}{\printdate{2023-03-16}}%chktex 8
\section{Lecture 18: Two-Way Crossed Classification (No Interaction)}
Model: $ Y_{ij}+\mu+\alpha_i+\beta_j+\varepsilon_{ij} $. We know that
$ \sum_{i=1}^{a}\alpha=0 $ and $ \sum_{j=1}^{b}\beta_j=0 $.
\begin{align*}
    \SST
     & =\sum_{i=1}^{a}\sum_{j=1}^{b}Y_{ij}^2-\frac{Y_{..}^2}{n}.                                                                                                                     \\
    \text{SS}(\alpha,\beta\mid \mu)
     & =\Vector{\beta}_0'\Matrix{X}'\Vector{Y}-\frac{Y_{..}^2}{n}                                                                                                                    \\
     & =\Vector{\beta}_0'\begin{pmatrix}
                             Y_{..}              \\
                             \Vector{Y}_{a.}     \\
                             \Vector{Y}_{.(b-1)} \\
                             \Vector{Y}_{.b}
                         \end{pmatrix}                                                                                                                                         \\
     & =\begin{pmatrix}
            \Matrix{O}                                                    &
            ( \Vector{\bar{Y}}_{a.}-\Matrix{M}\Matrix{C}^{-1}\Vector{r})' &
            ( \Matrix{C}^{-1}\Vector{r} )'                                &
            \Matrix{O}
        \end{pmatrix}\begin{pmatrix}
                         Y_{..}              \\
                         \Vector{Y}_{a.}     \\
                         \Vector{Y}_{.(b-1)} \\
                         \Vector{Y}_{.b}
                     \end{pmatrix}                                                                                                \\
     & =(\Matrix{D}_{a.}^{-1}\Vector{Y}_{a.}-\Matrix{M}\Matrix{C}^{-1}\Vector{r})'\Vector{Y}_{a.}+(\Matrix{C}^{-1}\Vector{r})'\Vector{Y}_{.(b-1)}-\frac{Y_{..}^2}{n}                 \\
     & =\Vector{Y}_{a.}'\Matrix{D}_{a.}^{-1}\Vector{Y}_{a.}-(\Matrix{M}\Matrix{C}^{-1}\Vector{r})'\Vector{Y}_{a.}+(\Matrix{C}^{-1}\Vector{r})'\Vector{Y}_{.(b-1)}-\frac{Y_{..}^2}{n} \\
     & =\sum_{i=1}^{a}\frac{Y_{i.}^2}{n_{i.}}+(\Matrix{C}^{-1}\Vector{r})'(\Vector{Y}_{.(b-1)}-\Matrix{M}'\Vector{Y}_{a.})-\frac{Y_{..}^2}{n}                                        \\
     & =\sum_{i=1}^{a}\frac{Y_{i.}^2}{n_{i.}}+\Vector{\beta}_{b-1}'\Vector{r}-\frac{Y_{..}^2}{n},
\end{align*}
where $ \Matrix{C}^{-1}\Vector{r}=\Vector{\beta}_{b-1} $.
Therefore,
\begin{itemize}
    \item $\text{SS}(\alpha\mid \mu)=\sum_{i=1}^{a}\frac{Y_{i.}^2}{n_{i.}}-\frac{Y_{..}^2}{n}$.
    \item $ \text{SS}(\beta\mid \mu,\alpha)=\text{SS}(\alpha,\beta\mid \mu)-\text{SS}(\alpha\mid \mu)=\Vector{\beta}_{b-1}'\Vector{r} $.
\end{itemize}
\subsection*{ANOVA Table I}
\[ \begin{array}{lllll}
        \toprule
        \text{Source of Variation}                   & \text{Degrees of Freedom} & \text{Sum of Squares}           & \text{Mean Square}              & F                       \\
        \midrule
        \text{Fitting }\alpha,\beta\text{ after }\mu & a+b-2                     & \text{SS}(\alpha,\beta\mid \mu) & \text{MS}(\alpha,\beta\mid \mu) & F(\alpha,\beta\mid \mu) \\
        \text{Error}                                 & n-(a+b-1)                 & \SSE                            & \MSE                                                      \\
        \midrule
        \text{Total}                                 & n-1                       & \SST                                                                                        \\
        \bottomrule
    \end{array} \]
$ F(\alpha,\beta\mid \mu)=\text{MS}(\alpha,\beta\mid \mu)/\MSE\sim F(a+b-2,n+1-a-b) $.
\subsection*{ANOVA Table II}
\[ \begin{array}{lllll}
        \toprule
        \text{Source of Variation}                    & \text{Degrees of Freedom} & \text{Sum of Squares}           & \text{Mean Square}              & F              \\
        \midrule
        \text{Fitting }\alpha\text{ after }\mu        & a-1                       & \text{SS}(\alpha\mid \mu)       & \text{MS}(\alpha\mid \mu)       & F(a-1,n+1-a-b) \\
        \text{Fitting }\beta \text{ after }\mu,\alpha & b-1                       & \text{SS}(\beta\mid \mu,\alpha) & \text{MS}(\beta\mid \mu,\alpha) & F(b-1,n+1-a-b) \\
        \text{Error}                                  & n+1-a-b                   & \SSE                            & \MSE                                             \\
        \midrule
        \text{Total}                                  & n-1                       & \SST                                                                               \\
        \bottomrule
    \end{array} \]
\subsection*{ANOVA Table III}
\[ \begin{array}{lllll}
        \toprule
        \text{Source of Variation}                    & \text{Degrees of Freedom} & \text{Sum of Squares}           & \text{Mean Square}              & F              \\
        \midrule
        \text{Fitting }\beta\text{ after }\mu         & b-1                       & \text{SS}(\beta\mid \mu)        & \text{MS}(\beta\mid \mu)        & F(b-1,n+1-a-b) \\
        \text{Fitting }\alpha \text{ after }\mu,\beta & a-1                       & \text{SS}(\alpha\mid \mu,\beta) & \text{MS}(\alpha\mid \mu,\beta) & F(a-1,n+1-a-b) \\
        \text{Error}                                  & n+1-a-b                   & \SSE                            & \MSE                                             \\
        \midrule
        \text{Total}                                  & n-1                       & \SST                                                                               \\
        \bottomrule
    \end{array} \]
\begin{itemize}
    \item $ \text{SS}(\beta\mid \mu) =\sum_{j=1}^{b}\frac{Y_{.j}^2}{n_{.j}}-\frac{Y_{..}^2}{n} $.
    \item $ \text{SS}(\alpha\mid \mu,\beta) =\text{SS}(\alpha,\beta\mid \mu)-\text{SS}(\beta\mid \mu) $.
\end{itemize}
\subsection*{Estimable Functions}
\[ \E{Y_{ij}}=\mu+\alpha_i+\beta_j =\sum_{i,j}w_{ij}(\mu+\alpha_i+\beta_j). \]
\begin{enumerate}[(1)]
    \item $ \mu+\alpha_i+\beta_j $ is estimable for all $ i,j $. Choose $ w_{ij}=1 $ and $ w_{k\ell}=0 $ for $ k\ne i $ or $ \ell\ne j $.
    \item $ \alpha_i-\alpha_k $ is estimable for all $ i\ne k $. Choose $ w_{ij}=-w_{kj}=1 $, other $ w_{k\ell}=0 $.
    \item $ \beta_k-\beta_\ell $ is estimable for all $ k\ne \ell $. Choose $ w_{ik}=-w_{i\ell}=1 $ and other coefficients $ 0 $.
\end{enumerate}
\begin{Example}{}{}
    Number of seconds beyond 3 minutes taken to boil 8 cups of water.
    \[ \begin{array}{cccc}
                                            & \multicolumn{3}{c}{\text{Make of Pan } (\beta)}           \\
            \text{Brand of Stove } (\alpha) & A                                               & B  & C  \\
            X                               & 18                                              & 12 & 24 \\
            Y                               & -                                               & -  & 9  \\
            Z                               & 3                                               & -  & 15 \\
            W                               & 6                                               & 3  & 18
        \end{array} \]
    The model will be $ Y_{ij}=\mu+\alpha_i+\beta_j+\varepsilon_{ij} $.
    \[ \Vector{Y}=\begin{pmatrix}
            Y_{11} &
            Y_{12} &
            Y_{13} &
            Y_{23} &
            Y_{31} &
            Y_{33} &
            Y_{41} &
            Y_{42} &
            Y_{43}
        \end{pmatrix}' \]
    \[ \Matrix{X}=\begin{pNiceMatrix}[first-row,first-col]
             & \mu & \alpha_1 & \alpha_2 & \alpha_3 & \alpha_4 & \beta_1 & \beta_2 & \beta_3 \\
             & 1   & 1        & 0        & 0        & 0        & 1       & 0       & 0       \\
             & 1   & 1        & 0        & 0        & 0        & 0       & 1       & 0       \\
             & 1   & 1        & 0        & 0        & 0        & 0       & 0       & 1       \\
             & 1   & 0        & 1        & 0        & 0        & 0       & 0       & 1       \\
             & 1   & 0        & 0        & 1        & 0        & 1       & 0       & 0       \\
             & 1   & 0        & 0        & 1        & 0        & 0       & 0       & 1       \\
             & 1   & 0        & 0        & 0        & 1        & 1       & 0       & 1       \\
             & 1   & 0        & 0        & 0        & 1        & 0       & 1       & 0       \\
             & 1   & 0        & 0        & 0        & 1        & 0       & 0       & 1
        \end{pNiceMatrix}\in\R^{9\times 8} \]
    \begin{itemize}
        \item $ n=9 $.
        \item $ m=1+4+3=8 $.
        \item $ n_{..}=9 $.
        \item $ n_{1.}=3 $, $ n_{2.}=1 $, $ n_{3.}=2 $, $ n_{4.}=3 $.
        \item $ n_{.1}=3 $, $ n_{.2}=2 $, $ n_{.3}=4 $.
        \item $ a=4 $, $ b=3 $, so $ a>b $ (choose $ \mu=0 $, $ \alpha_1=0 $)
    \end{itemize}
    \[ \Matrix{X}'\Matrix{X}=\begin{pmatrix}
            9 & 3 & 1 & 2 & 3 & 3 & 2 & 4 \\
            3 & 3 & 0 & 0 & 0 & 1 & 1 & 1 \\
            1 & 0 & 1 & 0 & 0 & 0 & 0 & 1 \\
            2 & 0 & 0 & 2 & 0 & 1 & 0 & 1 \\
            3 & 0 & 0 & 0 & 3 & 1 & 1 & 1 \\
            3 & 1 & 0 & 1 & 1 & 3 & 0 & 0 \\
            2 & 1 & 0 & 0 & 1 & 0 & 2 & 0 \\
            4 & 1 & 1 & 1 & 1 & 0 & 0 & 4
        \end{pmatrix} \]
    \begin{itemize}
        \item $ \Matrix{D}_{a.}=\diag{3,1,2,3} $.
        \item $ \Matrix{N}=\begin{pmatrix}
                      1 & 1 \\
                      0 & 0 \\
                      1 & 0 \\
                      1 & 1
                  \end{pmatrix} $.
        \item $ \Matrix{M}=\Matrix{D}_{a.}^{-1}\Matrix{N}=\begin{pmatrix}
                      1/3 & 1/3 \\
                      0   & 0   \\
                      1/2 & 0   \\
                      1/3 & 1/3
                  \end{pmatrix} $.
        \item $ \Matrix{D}_{.(b-1)}=\begin{pmatrix}
                      3 & 0 \\
                      0 & 2
                  \end{pmatrix}$.
        \item $ \Matrix{C}=\Matrix{D}_{.(b-1)}-\Matrix{N}'\Matrix{D}_{a.}^{-1}\Matrix{N}=
                  \begin{pmatrix}
                      3 & 0 \\
                      0 & 2
                  \end{pmatrix}-\begin{pmatrix}
                      1 & 0 & 1 & 1 \\
                      1 & 0 & 0 & 1
                  \end{pmatrix}\begin{pmatrix}
                      1/3 & 1/3 \\
                      0   & 0   \\
                      1/2 & 0   \\
                      1/3 & 1/3
                  \end{pmatrix}=\begin{pmatrix}
                      11/6 & -4/6 \\
                      -4/6 & 8/6
                  \end{pmatrix} $.
        \item $ \Matrix{C}^{-1}=\frac{1}{12}\begin{pmatrix}
                      8 & 4  \\
                      4 & 11
                  \end{pmatrix} $.
        \item $ \Vector{\bar{Y}}_{a.}=(18,9,9,9)' $.
        \item $ \Vector{Y}_{a.}=(54,9,18,27)' $.
        \item $ \Vector{Y}_{.(b-1)}=(27,15)' $.
        \item $ \Vector{r}
                  =\Vector{Y}_{.(b-1)}-\Matrix{M}'\Vector{Y}_{a.}
                  =\begin{pmatrix}
                      27 \\
                      15
                  \end{pmatrix}-\begin{pmatrix}
                      1/3 & 0 & 1/2 & 1/3 \\
                      1/3 & 0 & 0   & 1/3
                  \end{pmatrix}\begin{pmatrix}
                      54 \\
                      9  \\
                      18 \\
                      27
                  \end{pmatrix}=\begin{pmatrix}
                      -9 \\
                      -12
                  \end{pmatrix}$.
    \end{itemize}
    Therefore, a solution is
    $ \Vector{\beta}_0=\begin{pmatrix}
            0 & 26 & 9 & 14 & 17 & -10 & -14 & 0
        \end{pmatrix}' $.
    A $ g $-inverse of $ \Matrix{X}'\Matrix{X} $ is
    \[ \Matrix{F}=\frac{1}{12}\begin{pmatrix}%if you see this code i don't know what's going on either
            0               & \begin{bmatrix}
                                  0 & 0 & 0 & 0
                              \end{bmatrix}     & \begin{bmatrix}
                                                      0 & 0
                                                  \end{bmatrix}             \\
            \begin{bmatrix}
                0 \\
                0 \\
                0 \\
                0
            \end{bmatrix} & \begin{bmatrix}
                                7 & 0  & 2 & 3 \\
                                0 & 12 & 0 & 0 \\
                                2 & 0  & 8 & 2 \\
                                3 & 0  & 2 & 7
                            \end{bmatrix}   & \begin{bmatrix}
                                                  -4 & -5 \\
                                                  0  & 0  \\
                                                  -4 & -2 \\
                                                  -4 & -5
                                              \end{bmatrix} & \begin{bmatrix}
                                                                  0 \\0\\0\\0
                                                              \end{bmatrix} \\
            \begin{bmatrix}
                0 \\
                0
            \end{bmatrix} & \begin{bmatrix}
                                -4 & 0 & -4 & -4 \\
                                -5 & 0 & -2 & -5
                            \end{bmatrix} & \begin{bmatrix}
                                                8 & 4  \\
                                                4 & 11
                                            \end{bmatrix} & 0                \\
            0               & \begin{bmatrix}
                                  0 & 0 & 0 & 0
                              \end{bmatrix}     & \begin{bmatrix}
                                                      0 & 0 & 0
                                                  \end{bmatrix} & 0
        \end{pmatrix}. \]
\end{Example}